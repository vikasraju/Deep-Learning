{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7acnOwCbYhG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import BatchNormalization, Conv2D,Conv2DTranspose,LeakyReLU,Activation,MaxPooling2D,UpSampling2D   \n",
        "from tensorflow.keras.layers import Flatten,Dense,Reshape, Input ,GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "import os\n",
        "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\"\n",
        "import pickle\n",
        "from imutils import build_montages\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.layers import concatenate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCR6Kd0cbYjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Mounting drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "directory = 'drive/My Drive/Auto Encoder data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOkL1uADbYmS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 50\n",
        "INIT_LR = 1e-3   # learning rate\n",
        "BS = 16          #batch size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6gripPLbYpI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Image data generator with some data augmentation\n",
        "datagen  = ImageDataGenerator(rescale= .1/255, validation_split= 0.2 ,rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UVxVFQFbYt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "traindatagen = datagen.flow_from_directory(directory= directory, target_size=(512,512), batch_size= BS,subset='training', class_mode= 'input' ) \n",
        "valdatagen = datagen.flow_from_directory(directory=directory, target_size=(512,512), batch_size= BS,subset='validation', class_mode= 'input' )        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gO4yHXjIdOcI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputShape = (512,512,3)\n",
        "inputs = Input(shape=inputShape)\n",
        "x = inputs\n",
        "chanDim = -1\n",
        "\n",
        "conv1 = Conv2D(32, (3, 3), strides=1, padding=\"same\")(x)\n",
        "x = LeakyReLU(alpha=0.2)(conv1)\n",
        "x = BatchNormalization(axis=chanDim)(x)\n",
        "\n",
        "conv2 = Conv2D(32, (3, 3), strides=1, padding=\"same\")(x)\n",
        "x = LeakyReLU(alpha=0.2)(conv2)\n",
        "x = BatchNormalization(axis=chanDim)(x)\n",
        "\n",
        "conv3 = Conv2D(32, (3, 3), strides=1, padding=\"same\")(x)\n",
        "x = LeakyReLU(alpha=0.2)(conv3)\n",
        "x = BatchNormalization(axis=chanDim)(x)\n",
        "\n",
        "\n",
        "x = MaxPooling2D((2,2),padding='same')(x)\n",
        "\n",
        "conv4 = Conv2D(64, (3, 3), strides=1, padding=\"same\")(x)\n",
        "x = LeakyReLU(alpha=0.2)(conv4)\n",
        "x = BatchNormalization(axis=chanDim)(x)\n",
        "\n",
        "conv5 = Conv2D(64, (3, 3), strides=1, padding=\"same\")(x)\n",
        "x = LeakyReLU(alpha=0.2)(conv5)\n",
        "x = BatchNormalization(axis=chanDim)(x)\n",
        "\n",
        "conv6 = Conv2D(64, (3, 3), strides=1, padding=\"same\")(x)\n",
        "x = LeakyReLU(alpha=0.2)(conv6)\n",
        "x = BatchNormalization(axis=chanDim)(x)\n",
        "\n",
        "x = MaxPooling2D((2,2),padding='same')(x)\n",
        "\n",
        "conv7 = Conv2D(128, (3, 3), strides=1, padding=\"same\")(x)\n",
        "x = LeakyReLU(alpha=0.2)(conv7)\n",
        "x = BatchNormalization(axis=chanDim)(x)\n",
        "\n",
        "conv8 = Conv2D(128, (3, 3), strides=1, padding=\"same\")(x)\n",
        "x = LeakyReLU(alpha=0.2)(conv8)\n",
        "x = BatchNormalization(axis=chanDim)(x)\n",
        "\n",
        "conv9 = Conv2D(128, (3, 3), strides=1, padding=\"same\")(x)\n",
        "x = LeakyReLU(alpha=0.2)(conv9)\n",
        "x = BatchNormalization(axis=chanDim)(x)\n",
        "\n",
        "x = MaxPooling2D((2,2),padding='same')(x)\n",
        "\n",
        "conv10 = Conv2D(128, (3, 3), strides=1, padding=\"same\")(x)\n",
        "x = LeakyReLU(alpha=0.2)(conv10)\n",
        "x = BatchNormalization(axis=chanDim)(x)\n",
        "\n",
        "conv11 = Conv2D(128, (3, 3), strides=1, padding=\"same\")(x)\n",
        "x = LeakyReLU(alpha=0.2)(conv11)\n",
        "x = BatchNormalization(axis=chanDim)(x)\n",
        "\n",
        "conv12 = Conv2D(128, (3, 3), strides=1, padding=\"same\")(x)\n",
        "x = LeakyReLU(alpha=0.2)(conv12)\n",
        "x = BatchNormalization(axis=chanDim)(x)\n",
        "\n",
        "x = MaxPooling2D((2,2),padding='same')(x)\n",
        "\n",
        "conv13 = Conv2D(128, (3, 3), strides=1, padding=\"same\")(x)\n",
        "x = LeakyReLU(alpha=0.2)(conv13)\n",
        "x = BatchNormalization(axis=chanDim)(x)\n",
        "\n",
        "conv14 = Conv2D(128, (3, 3), strides=1, padding=\"same\")(x)\n",
        "x = LeakyReLU(alpha=0.2)(conv14)\n",
        "x = BatchNormalization(axis=chanDim)(x)\n",
        "\n",
        "conv15 = Conv2D(128, (3, 3), strides=1, padding=\"same\")(x)\n",
        "x = LeakyReLU(alpha=0.2)(conv15)\n",
        "x = BatchNormalization(axis=chanDim)(x)\n",
        "\n",
        "\n",
        "encoded = MaxPooling2D((2,2),padding='same',name=\"encoded\")(x)\n",
        "\n",
        "\n",
        "# start building the decoder model which will accept the\n",
        "# output of the encoder as its inputs\n",
        "\n",
        "\n",
        "x = UpSampling2D((2,2))(encoded)\n",
        "\n",
        "conv15 = Conv2D(128, (3, 3), strides=1, padding=\"same\")(x)\n",
        "x = LeakyReLU(alpha=0.2)(conv15)\n",
        "x = BatchNormalization(axis=chanDim)(x)\n",
        "\n",
        "conv14 = Conv2D(128, (3, 3), strides=1, padding=\"same\")(x)\n",
        "x = LeakyReLU(alpha=0.2)(conv14)\n",
        "x = BatchNormalization(axis=chanDim)(x)\n",
        "\n",
        "conv13 = Conv2D(128, (3, 3), strides=1, padding=\"same\")(x)\n",
        "x = LeakyReLU(alpha=0.2)(conv13)\n",
        "x = BatchNormalization(axis=chanDim)(x)\n",
        "\n",
        "x = UpSampling2D((2,2))(x)\n",
        "\n",
        "conv12 = Conv2D(128, (3, 3), strides=1, padding=\"same\")(x)\n",
        "x = LeakyReLU(alpha=0.2)(conv12)\n",
        "x = BatchNormalization(axis=chanDim)(x)\n",
        "\n",
        "conv11 = Conv2D(128, (3, 3), strides=1, padding=\"same\")(x)\n",
        "x = LeakyReLU(alpha=0.2)(conv11)\n",
        "x = BatchNormalization(axis=chanDim)(x)\n",
        "\n",
        "conv10 = Conv2D(128, (3, 3), strides=1, padding=\"same\")(x)\n",
        "x = LeakyReLU(alpha=0.2)(conv10)\n",
        "x = BatchNormalization(axis=chanDim)(x)\n",
        "\n",
        "x = UpSampling2D((2,2))(x)\n",
        "\n",
        "conv9 = Conv2D(128, (3, 3), strides=1, padding=\"same\")(x)\n",
        "x = LeakyReLU(alpha=0.2)(conv9)\n",
        "x = BatchNormalization(axis=chanDim)(x)\n",
        "\n",
        "conv8 = Conv2D(128, (3, 3), strides=1, padding=\"same\")(x)\n",
        "x = LeakyReLU(alpha=0.2)(conv8)\n",
        "x = BatchNormalization(axis=chanDim)(x)\n",
        "\n",
        "conv7 = Conv2D(128, (3, 3), strides=1, padding=\"same\")(x)\n",
        "x = LeakyReLU(alpha=0.2)(conv7)\n",
        "x = BatchNormalization(axis=chanDim)(x)\n",
        "\n",
        "x = UpSampling2D((2,2))(x)\n",
        "\n",
        "conv6 = Conv2D(64, (3, 3), strides=1, padding=\"same\")(x)\n",
        "x = LeakyReLU(alpha=0.2)(conv6)\n",
        "x = BatchNormalization(axis=chanDim)(x)\n",
        "\n",
        "conv5 = Conv2D(64, (3, 3), strides=1, padding=\"same\")(x)\n",
        "x = LeakyReLU(alpha=0.2)(conv5)\n",
        "x = BatchNormalization(axis=chanDim)(x)\n",
        "\n",
        "conv4 = Conv2D(64, (3, 3), strides=1, padding=\"same\")(x)\n",
        "x = LeakyReLU(alpha=0.2)(conv4)\n",
        "x = BatchNormalization(axis=chanDim)(x)\n",
        "\n",
        "\n",
        "x = UpSampling2D((2,2))(x)\n",
        "\n",
        "conv3 = Conv2D(32, (3, 3), strides=1, padding=\"same\")(x)\n",
        "x = LeakyReLU(alpha=0.2)(conv3)\n",
        "x = BatchNormalization(axis=chanDim)(x)\n",
        "\n",
        "conv2 = Conv2D(32, (3, 3), strides=1, padding=\"same\")(x)\n",
        "x = LeakyReLU(alpha=0.2)(conv2)\n",
        "x = BatchNormalization(axis=chanDim)(x)\n",
        "\n",
        "conv1 = Conv2D(32, (3, 3), strides=1, padding=\"same\")(x)\n",
        "x = LeakyReLU(alpha=0.2)(conv1)\n",
        "x = BatchNormalization(axis=chanDim)(x)\n",
        "\n",
        "\n",
        "x = Conv2D(3, (3, 3), padding=\"same\")(x)\n",
        "outputs = Activation(\"sigmoid\", name=\"decoded\")(x)\n",
        "\n",
        "# construct our autoencoder model\n",
        "autoencoder = Model(inputs, outputs, name=\"autoencoder\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t01TLjq6bYwu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M24cLaTtbYzQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Checkpoint when ther is an improvement in the model\n",
        "filepath=\"drive/My Drive/Auto Encoder Models/best2/weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "mc = ModelCheckpoint(filepath, monitor='val_accuracy',verbose=1, mode='max', save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOyojvIPbY12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Adam optimizier with initial learning rate =0.001\n",
        "opt = Adam(lr=INIT_LR)\n",
        "autoencoder.compile(loss=\"mse\", optimizer=opt, metrics= ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSdUrsjRbY4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Model Training\n",
        "History = autoencoder.fit(traindatagen,validation_data=valdatagen,epochs=EPOCHS,callbacks=[mc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DV5M_42ibY7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Saving the model \n",
        "autoencoder.save('drive/My Drive/Auto Encoder Models/3/model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "771FuSn9bY-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbY7_topbZBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}